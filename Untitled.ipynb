{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T08:45:23.360232Z",
     "start_time": "2019-03-28T08:45:23.331838Z"
    }
   },
   "outputs": [
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'job_name' is defined twice. First from /home/rs/.virtualenvs/science/lib/python3.5/site-packages/ipykernel_launcher.py, Second from /home/rs/.virtualenvs/science/lib/python3.5/site-packages/ipykernel_launcher.py.  Description from first occurrence: Either 'ps' or 'worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-90f2ffa9a603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# input flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Either 'ps' or 'worker'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"task_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Index of task within the job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/science/lib/python3.5/site-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/science/lib/python3.5/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[0;34m(name, default, help, flag_values, **args)\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m   \u001b[0mDEFINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/science/lib/python3.5/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \"\"\"\n\u001b[1;32m     81\u001b[0m   DEFINE_flag(_flag.Flag(parser, serializer, name, default, help, **args),\n\u001b[0;32m---> 82\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/science/lib/python3.5/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/science/lib/python3.5/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'job_name' is defined twice. First from /home/rs/.virtualenvs/science/lib/python3.5/site-packages/ipykernel_launcher.py, Second from /home/rs/.virtualenvs/science/lib/python3.5/site-packages/ipykernel_launcher.py.  Description from first occurrence: Either 'ps' or 'worker'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Distributed Tensorflow 1.2.0 example of using data parallelism and share model parameters.\n",
    "Trains a simple sigmoid neural network on mnist for 20 epochs on three machines using one parameter server. \n",
    "\n",
    "Change the hardcoded host urls below with your own hosts. \n",
    "Run like this: \n",
    "\n",
    "pc-01$ python example.py --job_name=\"ps\" --task_index=0 \n",
    "pc-02$ python example.py --job_name=\"worker\" --task_index=0 \n",
    "pc-03$ python example.py --job_name=\"worker\" --task_index=1 \n",
    "pc-04$ python example.py --job_name=\"worker\" --task_index=2 \n",
    "\n",
    "More details here: ischlag.github.io\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# cluster specification\n",
    "parameter_servers = [\"pc-01:2222\"]\n",
    "workers = [\t\"pc-02:2222\", \n",
    "            \"pc-03:2222\",\n",
    "            \"pc-04:2222\"]\n",
    "cluster = tf.train.ClusterSpec({\"ps\":parameter_servers, \"worker\":workers})\n",
    "\n",
    "# input flags\n",
    "tf.app.flags.DEFINE_string(\"job_name\", \"\", \"Either 'ps' or 'worker'\")\n",
    "tf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# start a server for a specific task\n",
    "server = tf.train.Server(\n",
    "    cluster,\n",
    "    job_name=FLAGS.job_name,\n",
    "    task_index=FLAGS.task_index)\n",
    "\n",
    "# config\n",
    "batch_size = 100\n",
    "learning_rate = 0.0005\n",
    "training_epochs = 20\n",
    "logs_path = \"/tmp/mnist/1\"\n",
    "\n",
    "# load mnist data set\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "if FLAGS.job_name == \"ps\":\n",
    "    server.join()\n",
    "elif FLAGS.job_name == \"worker\":\n",
    "\n",
    "    # Between-graph replication\n",
    "    with tf.device(tf.train.replica_device_setter(\n",
    "        worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n",
    "        cluster=cluster)):\n",
    "\n",
    "        # count the number of updates\n",
    "        global_step = tf.get_variable(\n",
    "            'global_step',\n",
    "            [],\n",
    "            initializer = tf.constant_initializer(0),\n",
    "            trainable = False)\n",
    "\n",
    "        # input images\n",
    "        with tf.name_scope('input'):\n",
    "          # None -> batch size can be any size, 784 -> flattened mnist image\n",
    "          x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x-input\")\n",
    "          # target 10 output classes\n",
    "          y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y-input\")\n",
    "\n",
    "        # model parameters will change during training so we use tf.Variable\n",
    "        tf.set_random_seed(1)\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            W1 = tf.Variable(tf.random_normal([784, 100]))\n",
    "            W2 = tf.Variable(tf.random_normal([100, 10]))\n",
    "\n",
    "        # bias\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            b1 = tf.Variable(tf.zeros([100]))\n",
    "            b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "        # implement model\n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            # y is our prediction\n",
    "            z2 = tf.add(tf.matmul(x,W1),b1)\n",
    "            a2 = tf.nn.sigmoid(z2)\n",
    "            z3 = tf.add(tf.matmul(a2,W2),b2)\n",
    "            y  = tf.nn.softmax(z3)\n",
    "\n",
    "        # specify cost function\n",
    "        with tf.name_scope('cross_entropy'):\n",
    "            # this is our cost\n",
    "            cross_entropy = tf.reduce_mean(\n",
    "                -tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "        # specify optimizer\n",
    "        with tf.name_scope('train'):\n",
    "            # optimizer is an \"operation\" which we can execute in a session\n",
    "            grad_op = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "            '''\n",
    "            rep_op = tf.train.SyncReplicasOptimizer(\n",
    "                grad_op,\n",
    "                replicas_to_aggregate=len(workers),\n",
    "                replica_id=FLAGS.task_index, \n",
    "                total_num_replicas=len(workers),\n",
    "                use_locking=True)\n",
    "            train_op = rep_op.minimize(cross_entropy, global_step=global_step)\n",
    "            '''\n",
    "            train_op = grad_op.minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "        '''\n",
    "        init_token_op = rep_op.get_init_tokens_op()\n",
    "        chief_queue_runner = rep_op.get_chief_queue_runner()\n",
    "        '''\n",
    "\n",
    "        with tf.name_scope('Accuracy'):\n",
    "            # accuracy\n",
    "            correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        # create a summary for our cost and accuracy\n",
    "        tf.summary.scalar(\"cost\", cross_entropy)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "        # merge all summaries into a single \"operation\" which we can execute in a session \n",
    "        summary_op = tf.summary.merge_all()\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        print(\"Variables initialized ...\")\n",
    "\n",
    "    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),\n",
    "                                                        global_step=global_step,\n",
    "                                                        init_op=init_op)\n",
    "\n",
    "    begin_time = time.time()\n",
    "    frequency = 100\n",
    "    with sv.prepare_or_wait_for_session(server.target) as sess:\n",
    "        '''\n",
    "        # is chief\n",
    "        if FLAGS.task_index == 0:\n",
    "            sv.start_queue_runners(sess, [chief_queue_runner])\n",
    "            sess.run(init_token_op)\n",
    "        '''\n",
    "        # create log writer object (this will log on every machine)\n",
    "        writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "        # perform training cycles\n",
    "        start_time = time.time()\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # number of batches in one epoch\n",
    "            batch_count = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "            count = 0\n",
    "            for i in range(batch_count):\n",
    "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                # perform the operations we defined earlier on batch\n",
    "                _, cost, summary, step = sess.run(\n",
    "                                                [train_op, cross_entropy, summary_op, global_step], \n",
    "                                                feed_dict={x: batch_x, y_: batch_y})\n",
    "                writer.add_summary(summary, step)\n",
    "\n",
    "                count += 1\n",
    "                if count % frequency == 0 or i+1 == batch_count:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    start_time = time.time()\n",
    "                    print(\"Step: %d,\" % (step+1), \n",
    "                                \" Epoch: %2d,\" % (epoch+1), \n",
    "                                \" Batch: %3d of %3d,\" % (i+1, batch_count), \n",
    "                                \" Cost: %.4f,\" % cost, \n",
    "                                \" AvgTime: %3.2fms\" % float(elapsed_time*1000/frequency))\n",
    "                    count = 0\n",
    "\n",
    "\n",
    "        print(\"Test-Accuracy: %2.2f\" % sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "        print(\"Total Time: %3.2fs\" % float(time.time() - begin_time))\n",
    "        print(\"Final Cost: %.4f\" % cost)\n",
    "\n",
    "    sv.stop()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
